# Automated Electric Meter Reader

A project that uses a custom-trainedÂ **YOLOv8**Â model to detect meter readings and serial numbers on electric meters, andÂ **Tesseract OCR**Â to extract the text from these regions.

This system automates the manual and error-prone process of meter reading by providing a fast and accurate pipeline that takes an image as input and returns a structured JSON object with the extracted data.

---

## Features

- **Object Detection:**Â Uses a custom-trained YOLOv8 model to accurately locate:
    
    - Meter Readings (Class 0)
        
    - Serial Numbers (Class 1)
        
- **Optical Character Recognition (OCR):**Â Employs Tesseract to extract text from the detected regions.
    
- **Structured Output:**Â Provides results in a simple, easy-to-parse JSON format, including confidence scores for each detection.
    
- **Modular:**Â Easy to swap in new models or change OCR configurations.
    

---

## How it Works

The project follows a two-stage pipeline:

1. **Detection:**Â The system loads the custom-trained YOLOv8 model (`best.pt`). An input image is passed to the model, which returns a list of bounding boxes for all detected objects (meter readings and serial numbers).
    
2. **Recognition:**Â For each detected bounding box:
    
    - The region isÂ **cropped**Â from the original image.
        
    - The crop is converted from an OpenCV format to a PIL (Pillow) image.
        
    - **Tesseract OCR**Â is run on the PIL image to extract the text. We useÂ `config="--psm 6"`Â which assumes the crop is a single uniform block of text.
        
    - The extracted text and the model's detection confidence score are stored.
        
3. **Output:**Â The final data is compiled and printed as a JSON object.
    

---

## ğŸ“¦ Project Structure

```
your-project-directory/
â”‚
â”œâ”€â”€ runs/detect/train/weights/
â”‚   â””â”€â”€ best.pt           # Your trained YOLOv8 model
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ ...               # Your training and test images
â”‚
â”œâ”€â”€ read_meter.py         # The main Python script (your code)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # This file
```

---

## ğŸ› ï¸ Requirements & Installation

### 1. Python Dependencies

This project requires the following Python libraries. You can install them all usingÂ `pip`.

```
ultralytics
opencv-python
pytesseract
pillow
```

Create aÂ `requirements.txt`Â file with the contents above and run:

Bash

```
pip install -r requirements.txt
```

### 2. Tesseract-OCR Engine

`pytesseract`Â is just a Python wrapper. You must install the Tesseract-OCR engine itself on your system.

**On macOS:**

Bash

```
brew install tesseract
```

**On Ubuntu/Debian:**

Bash

```
sudo apt update
sudo apt install tesseract-ocr
```

**On Windows:**Â Download and run the official installer from theÂ [Tesseract at UB-Mannheim](https://www.google.com/search?q=https://github.com/UB-Mannheim/tesseract/wiki)Â repository. Make sure to add the Tesseract installation directory to your system'sÂ `PATH`.

---

## ğŸš€ How to Run

The provided script (`read_meter.py`) is set up to run inference on a single, hardcoded image.

1. **Ensure paths are correct:**
    
    - Make sure the path to your YOLO model (`best.pt`) is correct.
        
    - Make sure theÂ `source`Â image path forÂ `model.predict()`Â and theÂ `cv2.imread()`Â path are correct.
        
2. **Execute the script:**
    
    Bash
    
    ```
    python read_meter.py
    ```
    

### Example Output

Running the script will process the image and print a JSON object to the console, similar to this:

JSON

```
{
    "meter_readings": [
        {
            "value": "123456",
            "confidence": 0.9458023309707642
        }
    ],
    "serial_number": [
        {
            "value": "SN987654",
            "confidence": 0.8912345170974731
        }
    ]
}
```

---

## ğŸ‹ï¸ Model Training

The model used (`best.pt`) was custom-trained using YOLOv8 on a labeled dataset of electric meter images.

- **Dataset:**Â The dataset was annotated with bounding boxes for two classes:
    
    - `0`:Â `meter_reading`
        
    - `1`:Â `serial_number`
        
- **Training:**Â The model was trained using theÂ `ultralytics`Â library. For information on how to train your own model, please refer to theÂ [official YOLOv8 documentation](https://docs.ultralytics.com/tasks/detect/).
    

---

## ğŸ’¡ Future Improvements

- **CLI Arguments:**Â Modify the script to accept the image path as a command-line argument instead of hardcoding it.
    
- **Image Pre-processing:**Â Add image pre-processing steps (e.g., grayscale, thresholding, denoising) to the cropped regionsÂ _before_Â sending them to Tesseract to improve OCR accuracy.
    
- **Web API:**Â Wrap the entire pipeline in a simple web API (using Flask or FastAPI) to allow for easy integration with other services.
    
- **Batch Processing:**Â Add functionality to process an entire directory of images instead of just one.
